{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c710d5-a266-4bf5-a84b-5ef3a5627907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from time import *\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output\n",
    "from pandas.io.html import read_html\n",
    "from urllib.request import Request, urlopen\n",
    "import urllib.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f492bb-ec86-4627-81c0-45a14be4698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.investing.com/search/?q=ibm&tab=news'\n",
    "response = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "response = urlopen(response).read()\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269cfd75-37ee-406a-ad68-869f39f4ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "article_containers = soup.findAll('div', class_ = 'articleItem')\n",
    "print(len(article_containers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f7a5ec-edfe-4783-aa62-c2a43c4cf12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM unveils Project Debater\n",
      "IBM holds shareholder meeting\n",
      "IBM strategy centering around data\n",
      "IBM Breakout\n",
      "IBM Earnings\n",
      "IBM Shares Looking Bearish\n",
      "{{title}}\n",
      "{{title}}\n"
     ]
    }
   ],
   "source": [
    "for article in article_containers:\n",
    "    print(article.div.a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd65287-ca9d-4e5f-8196-0382ea050fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url500 = 'https://www.investing.com/indices/us-spx-500-news/1'\n",
    "response = Request(url500, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "response = urlopen(response).read()\n",
    "soup = BeautifulSoup(response, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0982a2-ac64-4fde-a026-9d3fd28c64be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "article_containers = soup.findAll('div', class_ = 'mediumTitle1')\n",
    "print(len(article_containers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d251cf-6c3f-4bc6-99a5-48761823b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall St sinks as yields spike, financials fall after Goldman miss\n",
      " - 14 minutes ago\n",
      "S&P 500 Closes Lower as Banks, Tech Lead Sea of Red on Wall Street\n",
      " - 20 minutes ago\n",
      "S&P 500 on Back Foot as Goldman Leads Rout in Financials\n",
      " - 37 minutes ago\n",
      "Jump in Treasury yields sink equity markets, notably tech\n",
      " - 45 minutes ago\n",
      "Inverse ETFs Dominate as Stocks Struggle Again on Tuesday\n",
      " - 32 minutes ago\n",
      "RSP Right Idea for 2022 Diversification\n",
      " - 4 hours ago\n",
      "Deep Dive: This is the window of time when value can outperform growth in the stock market\n",
      " - 5 hours ago\n",
      "S&P 500 Takes Beating on Tuesday\n",
      " - 5 hours ago\n",
      "Brett Arends's ROI: Beware this ‘dangerous blessing’ for 401(k)s\n",
      " - 6 hours ago\n",
      "Wall Street Opens Lower on Earnings Misses, Inflation Fear; Dow Down 500 Pts\n",
      " - 6 hours ago\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1, len(article_containers)):\n",
    "    #print(article_containers[i].article.div.a.text)\n",
    "    article = article_containers[i].findAll('div', class_ = 'textDiv')\n",
    "    for a in article:\n",
    "        print(a.a.text)\n",
    "        date = a.find('span', class_ = 'date')\n",
    "        print(date.text)\n",
    "    #print(article)\n",
    "    #print(article.article.div.a.text)\n",
    "    print \n",
    "    #print(article.div.div)\n",
    "    #date = article.find('span', class_ = 'date')    \n",
    "    #print(date.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd13239-2577-4773-99fe-c3063c15422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = []\n",
    "dates = []\n",
    "requests = 0\n",
    "start_time = time()\n",
    "pages = [str(i) for i in range(1, 1700, 5)]\n",
    "for p in pages:\n",
    "    url = 'https://www.investing.com/indices/us-spx-500-news/' + p\n",
    "    print(p)\n",
    "    response = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    status = urlopen(response).status\n",
    "    response = urlopen(response).read()\n",
    "    sleep(randint(8, 15))\n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    #clear_output(wait = True)\n",
    "    if status != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    article_containers = soup.findAll('div', class_ = 'mediumTitle1')\n",
    "    for i in range(1, len(article_containers)):\n",
    "        article = article_containers[i].findAll('div', class_ = 'textDiv')\n",
    "        for a in article:\n",
    "            #print(a.a.text)\n",
    "            article_titles.append(a.a.text)\n",
    "            date = a.find('span', class_ = 'date')\n",
    "            dates.append(date.text)\n",
    "            #print(date.text)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84325b5-0d82-435c-9448-53604ff91e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7524c2-5d1e-4520-a8b0-9ff8d61f3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e901c0b-edbe-4138-af05-7d6508c4bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 1700, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37cbae8f-ff35-4833-89ad-56980843cc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article Titles</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. stocks lower at close of trade; Dow Jones...</td>\n",
       "      <td>- 27 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks sink, notably tech, as Treasury yields ...</td>\n",
       "      <td>- 1 hour ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S&amp;P 500 Closes Lower as Banks, Tech Lead Sea o...</td>\n",
       "      <td>- 1 hour ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S&amp;P 500 on Back Foot as Goldman Leads Rout in ...</td>\n",
       "      <td>- 2 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inverse ETFs Dominate as Stocks Struggle Again...</td>\n",
       "      <td>- 2 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>US STOCKS-Utilities advance market as leadersh...</td>\n",
       "      <td>- May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>US STOCKS-Utilities lift Wall Street as leader...</td>\n",
       "      <td>- May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3393</th>\n",
       "      <td>US STOCKS-Wall St rises on China data, sector ...</td>\n",
       "      <td>- May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3394</th>\n",
       "      <td>US STOCKS-Wall St set to rise after strong Chi...</td>\n",
       "      <td>- May 10, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>US STOCKS-Futures gain after strong Chinese data</td>\n",
       "      <td>- May 10, 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3396 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Article Titles               Date\n",
       "0     U.S. stocks lower at close of trade; Dow Jones...   - 27 minutes ago\n",
       "1     Stocks sink, notably tech, as Treasury yields ...       - 1 hour ago\n",
       "2     S&P 500 Closes Lower as Banks, Tech Lead Sea o...       - 1 hour ago\n",
       "3     S&P 500 on Back Foot as Goldman Leads Rout in ...      - 2 hours ago\n",
       "4     Inverse ETFs Dominate as Stocks Struggle Again...      - 2 hours ago\n",
       "...                                                 ...                ...\n",
       "3391  US STOCKS-Utilities advance market as leadersh...     - May 10, 2011\n",
       "3392  US STOCKS-Utilities lift Wall Street as leader...     - May 10, 2011\n",
       "3393  US STOCKS-Wall St rises on China data, sector ...     - May 10, 2011\n",
       "3394  US STOCKS-Wall St set to rise after strong Chi...     - May 10, 2011\n",
       "3395   US STOCKS-Futures gain after strong Chinese data     - May 10, 2011\n",
       "\n",
       "[3396 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([article_titles, dates]).T\n",
    "df.columns = ['Article Titles', 'Date']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a04ada9-475d-43cd-bed4-bb81473c3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sp500news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27180cf5-ecd6-4b7e-b331-c07ec4e0df1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. stocks lower at close of trade; Dow Jones Industrial Average down 1.51%'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['Article Titles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f58436e-a149-4429-ac03-e5324837b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect company news url's\n",
    "url = 'https://www.investing.com/search/?q=aapl'\n",
    "response = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "response = urlopen(response).read()\n",
    "soup = BeautifulSoup(response, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a21dd5-d3fa-4ca5-ba8d-3d448dcdd565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.investing.com/equities/apple-computer-inc'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://www.investing.com' + soup.find('a', class_ = 'js-inner-all-results-quote-item row')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "833d3833-a556-41b7-b1bc-1aed7d09572b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       MMM\n",
       "1       AOS\n",
       "2       ABT\n",
       "3      ABBV\n",
       "4      ABMD\n",
       "       ... \n",
       "500     YUM\n",
       "501    ZBRA\n",
       "502     ZBH\n",
       "503    ZION\n",
       "504     ZTS\n",
       "Name: Symbol, Length: 505, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols = pd.read_csv('sp500.csv')['Symbol']\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558caaae-ef50-42fd-b86f-ac984d2d9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "requests = 0\n",
    "start_time = time()\n",
    "file = open(\"sp500news_urls.txt\", \"w\")\n",
    "for i in range(len(symbols)):\n",
    "    #url = 'https://www.investing.com/search/?q=' + symbols.iloc[i]\n",
    "    if symbols.iloc[i] == \"BRK.B\":\n",
    "        url = 'https://www.investing.com/search/?q=BRK-B'\n",
    "    elif symbols.iloc[i] == \"BF.B\":\n",
    "        url = 'https://www.investing.com/search/?q=BF-B'\n",
    "    else:\n",
    "        url = 'https://www.investing.com/search/?q=' + symbols.iloc[i]\n",
    "    print(symbols.iloc[i])\n",
    "    response = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    status = urlopen(response).status\n",
    "    response = urlopen(response).read()\n",
    "    sleep(randint(8, 15))\n",
    "    requests += 1\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "    if status != 200:\n",
    "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "    soup = BeautifulSoup(response, \"html.parser\")\n",
    "    url_container = 'https://www.investing.com' + soup.find('a', class_ = 'js-inner-all-results-quote-item row')['href'] + '-news'\n",
    "    file.write(url_container + \"\\n\")\n",
    "    print(url_container)\n",
    "    url_list.append(url_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba80f4cc-9d00-4611-bd2c-2ea22d0ff04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"sp500news_urls.txt\", \"r\")\n",
    "while file.readline():\n",
    "    print(file.readline()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05cb35b8-d8ab-4a5c-9e24-adf67a2e9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.investing.com/equities/apple-computer-inc-news'\n",
    "response = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "response = urlopen(response).read()\n",
    "soup = BeautifulSoup(response, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "971a74fd-0d44-4434-a430-6662effb7634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "article_containers = soup.findAll('div', class_ = 'mediumTitle1')\n",
    "print(len(article_containers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aeb3188-208a-4983-b3d6-9725eaca2352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peloton's collapse spins up Apple, Nike, Amazon acquisition chatter\n",
      " - 14 hours ago\n",
      "S&P 500, Nasdaq post worst weeks since pandemic start as Netflix woes deepen slide\n",
      " - Jan 21, 2022\n",
      "False\n",
      "Catalyst watch for next week: Earnings blitz headlined by Apple, Microsoft, Boeing and Tesla\n",
      " - Jan 21, 2022\n",
      "False\n",
      "Apple: Healthy Demand Merits a Price Target Hike, According to this Analyst\n",
      " - Jan 21, 2022\n",
      "False\n",
      "Apple, Microsoft are 'Rock of Gibraltar names' that will save tech - Wedbush analyst Dan Ives\n",
      " - Jan 21, 2022\n",
      "False\n",
      "Single stock options worth $1.2 trillion set to expire - Options Solutions\n",
      " - Jan 21, 2022\n",
      "False\n",
      "iPhone maker Foxconn seals EV partnership with Indonesia\n",
      " - Jan 21, 2022\n",
      "False\n",
      "Snap plays up augmented reality in Latin America, Asia expansion\n",
      " - Jan 21, 2022\n",
      "False\n",
      "Apple on Track to Beat Earnings Estimates Again; Target Price $210 in Best Case\n",
      " - Jan 21, 2022\n",
      "False\n",
      "Take Five: All about inflation\n",
      " - Jan 21, 2022\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, len(article_containers)):\n",
    "    #print(article_containers[i].article.div.a.text)\n",
    "    article = article_containers[i].findAll('div', class_ = 'textDiv')\n",
    "    year = None\n",
    "    for a in article:\n",
    "        print(a.a.text)\n",
    "        date = a.find('span', class_ = 'date')\n",
    "        print(date.text)\n",
    "        if date.text[len(date.text) - 4:] != ' ago':\n",
    "            print(int(date.text[-4:]) < 2020)\n",
    "next_page = soup.find('div', class_ = 'sideDiv inlineblock text_align_lang_base_2')\n",
    "next_page.a == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccd52b7e-7444-4ed3-ab89-5608c2decc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "2022\n",
      "2021\n",
      "2021\n",
      "2021\n",
      "2021\n",
      "2021\n",
      "2021\n",
      "2021\n",
      "2021\n",
      "----------------------Finished-------------------------\n"
     ]
    }
   ],
   "source": [
    "article_titles = []\n",
    "dates = []\n",
    "companies = []\n",
    "requests = 0\n",
    "start_time = time()\n",
    "pages = [str(i) for i in range(1, 1500, 2)]\n",
    "file = open(\"sp500news_urls.txt\", \"r\")\n",
    "fwrite = open(\"company_news.txt\", \"a\")\n",
    "lines = file.readlines()\n",
    "for x in range(len(lines)):\n",
    "    old_year = 2022\n",
    "    d = {}\n",
    "    for p in pages:\n",
    "        #if x == 22 and int(p) < 751:\n",
    "        #    continue\n",
    "        if ((int(p) - 1) % 5) == 0 or ((int(p) - 1) % 3 == 0):\n",
    "            continue\n",
    "        print(x, p)\n",
    "        companies.append(symbols.iloc[x])\n",
    "        url = lines[x][:len(lines[x]) - 1] + '/' + p\n",
    "        print(url)\n",
    "        try:\n",
    "            response = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"}) \n",
    "            status = urlopen(response).status\n",
    "            response = urlopen(response).read()\n",
    "        except:\n",
    "            continue\n",
    "        sleep(randint(5, 12))\n",
    "        requests += 1\n",
    "        elapsed_time = time() - start_time\n",
    "        print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n",
    "        clear_output(wait = True)\n",
    "        if status != 200:\n",
    "            warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
    "        soup = BeautifulSoup(response, \"html.parser\")\n",
    "        article_containers = soup.findAll('div', class_ = 'mediumTitle1')\n",
    "        #year = 2022\n",
    "        if x == 0 and p == '1':\n",
    "            print(\"TEST\")\n",
    "            fwrite = open(\"company_news.txt\", \"a\")\n",
    "        else:\n",
    "            fwrite = open(\"company_news.txt\", \"a\")\n",
    "        new_year = 2022\n",
    "        flag = False\n",
    "        for i in range(1, len(article_containers)):\n",
    "            article = article_containers[i].findAll('div', class_ = 'textDiv')\n",
    "            for a in article:\n",
    "                article_titles.append(a.a.text)\n",
    "                date = a.find('span', class_ = 'date')\n",
    "                dates.append(date.text)\n",
    "                if date.text[len(date.text) - 4:] != ' ago' and date.text[len(date.text) - 4:] != ' Now':\n",
    "                    new_year = int(date.text[len(date.text) - 4:])\n",
    "                    print(new_year)\n",
    "                    if new_year < 2015:\n",
    "                        break\n",
    "                #print(date.text)\n",
    "                if a.a.text in d:\n",
    "                    flag = True\n",
    "                    break\n",
    "                fwrite.write(symbols.iloc[x] + \", \" + a.a.text + \", \" + date.text + \"\\n\")\n",
    "                if int(p) == 1:\n",
    "                    d[a.a.text] = date.text\n",
    "            if flag == True:\n",
    "                break\n",
    "            if new_year < 2015:\n",
    "                break\n",
    "        fwrite.close()\n",
    "        if flag == True:\n",
    "            break\n",
    "        next_page = soup.find('div', class_ = 'sideDiv inlineblock text_align_lang_base_2')\n",
    "        #print(next_page.a, year)\n",
    "        if next_page == None or next_page.a == None or new_year < 2015 or new_year > old_year:\n",
    "            print(\"----------------------Finished-------------------------\")\n",
    "            break\n",
    "        old_year = new_year\n",
    "        \n",
    "fwrite.close()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab6919c0-215e-4a7e-87ef-a0030e84780f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 4 fields in line 3, saw 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1183/3996670423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"company_news.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 4 fields in line 3, saw 5\n"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"company_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d24f336-6e0b-4b3c-b33b-2fb4bdc107fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_titles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1196/4232859235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_titles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'article_titles' is not defined"
     ]
    }
   ],
   "source": [
    "len(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1178562-22e6-433e-b5a0-c1f83873b5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15170"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d078adc-1fdf-4039-a027-5556a94a0db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(550, len(dates)):\n",
    "    companies.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afacee55-13a9-4ced-bd9f-463722660abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: Align Technology stock price target cut to $...</td>\n",
       "      <td>- Jan 21, 2022</td>\n",
       "      <td>ALGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Align Technology ticks lower on new short repo...</td>\n",
       "      <td>- Jan 06, 2022</td>\n",
       "      <td>ALGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baird bullish on dental stocks for 2022 with A...</td>\n",
       "      <td>- Jan 03, 2022</td>\n",
       "      <td>ALGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 Top Large-Cap Growth Stocks to Buy Before 2022</td>\n",
       "      <td>- Dec 13, 2021</td>\n",
       "      <td>ALGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wells Fargo Stick to Their Buy Rating for Atla...</td>\n",
       "      <td>- Dec 09, 2021</td>\n",
       "      <td>ALGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15165</th>\n",
       "      <td>Short Interest in Align Technology, Inc. (NASD...</td>\n",
       "      <td>- Dec 04, 2021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15166</th>\n",
       "      <td>Lululemon fires back at Peloton lawsuit with i...</td>\n",
       "      <td>- Nov 30, 2021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15167</th>\n",
       "      <td>Robert W. Baird Stick to Their Buy Rating for ...</td>\n",
       "      <td>- Nov 02, 2021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15168</th>\n",
       "      <td>Align Earnings, Revenue Beat in Q3</td>\n",
       "      <td>- Oct 27, 2021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15169</th>\n",
       "      <td>Wells Fargo Stick to Their Buy Rating for Atla...</td>\n",
       "      <td>- Oct 21, 2021</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15170 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0                1  \\\n",
       "0      : Align Technology stock price target cut to $...   - Jan 21, 2022   \n",
       "1      Align Technology ticks lower on new short repo...   - Jan 06, 2022   \n",
       "2      Baird bullish on dental stocks for 2022 with A...   - Jan 03, 2022   \n",
       "3       4 Top Large-Cap Growth Stocks to Buy Before 2022   - Dec 13, 2021   \n",
       "4      Wells Fargo Stick to Their Buy Rating for Atla...   - Dec 09, 2021   \n",
       "...                                                  ...              ...   \n",
       "15165  Short Interest in Align Technology, Inc. (NASD...   - Dec 04, 2021   \n",
       "15166  Lululemon fires back at Peloton lawsuit with i...   - Nov 30, 2021   \n",
       "15167  Robert W. Baird Stick to Their Buy Rating for ...   - Nov 02, 2021   \n",
       "15168                 Align Earnings, Revenue Beat in Q3   - Oct 27, 2021   \n",
       "15169  Wells Fargo Stick to Their Buy Rating for Atla...   - Oct 21, 2021   \n",
       "\n",
       "          2  \n",
       "0      ALGN  \n",
       "1      ALGN  \n",
       "2      ALGN  \n",
       "3      ALGN  \n",
       "4      ALGN  \n",
       "...     ...  \n",
       "15165  None  \n",
       "15166  None  \n",
       "15167  None  \n",
       "15168  None  \n",
       "15169  None  \n",
       "\n",
       "[15170 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([article_titles, dates, companies]).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d918e82-c604-465e-ae97-4001165de30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ALGN', None], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[2].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da74d6d9-5373-4562-8ea1-61fcb70c9b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ec07e99-be09-4d82-a444-486cf01ea937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44    AAPL\n",
       "Name: Symbol, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[symbols == 'AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2293deb7-50e2-43ef-bf1e-c10953c445c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwrite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e985020-a7de-479c-82e0-1c91de6988ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
